{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from ibm_watson import AssistantV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import pandas as pd    \n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator('')\n",
    "assistant = AssistantV2(\n",
    "    version='2020-04-01',\n",
    "    authenticator = authenticator\n",
    ")\n",
    "assistant.set_service_url('https://api.eu-gb.assistant.watson.cloud.ibm.com')\n",
    "assistant_id = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ResponseList = []\n",
    "IntentList = []\n",
    "QuestionList = []\n",
    "ConfidenceList = []\n",
    "ExpectedList = []\n",
    "SecondIntent = []\n",
    "SecondConfidence = []\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "\n",
    "RegressionFile = pd.read_csv(\"Regression.csv\")\n",
    "RegressionLog = pd.read_csv(\"RegressionLog.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Historic files into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load files into useable lists for the regression file\n",
    "\n",
    "\n",
    "QuestionList = RegressionFile['Question'].tolist()\n",
    "ExpectedList = RegressionFile['Expected'].tolist()\n",
    "ScoreList = RegressionFile['Previous Score'].tolist()\n",
    "\n",
    "#Load in historic results.\n",
    "HistoricMatchConfidence = RegressionLog['Match Confidence']\n",
    "HistoricUnmatchConfidence = RegressionLog['Unmatched Confidence']\n",
    "HistoricAverageConfidence = RegressionLog['Average Confidence']\n",
    "HistoricCorrectResponse = RegressionLog['Correct Response %']\n",
    "HistoricLowConfidence = RegressionLog['Low Confidence']\n",
    "HistoricDate = RegressionLog['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send questions to Watson and log the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def Sender():\n",
    "    response = assistant.message_stateless(\n",
    "    assistant_id,\n",
    "    input={\n",
    "        'message_type': 'text',\n",
    "        'text': x,\n",
    "     'options': {\n",
    "            'return_context': True\n",
    "        }\n",
    "    },\n",
    "    context={\n",
    "        'skills': {\n",
    "            'main skill': {\n",
    "                'user_defined': {\n",
    "                    'ConfidenceTester': 'Yes'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ").get_result()\n",
    "    pbar.update(1) #Updates the progressbar\n",
    "    IntentList.append((response['context']['skills']['main skill']['user_defined']['Intent']['intent']))\n",
    "    ConfidenceList.append((response['context']['skills']['main skill']['user_defined']['Intent']['confidence']))\n",
    "    SecondIntent.append((response['context']['skills']['main skill']['user_defined']['Intent1']['intent']))\n",
    "    SecondConfidence.append((response['context']['skills']['main skill']['user_defined']['Intent1']['confidence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through and show progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pbar = tqdm(total=len(QuestionList),desc=\"Percentage complete\") \n",
    "for x in QuestionList:\n",
    "    Sender()\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn all the data into something usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MatchList = []\n",
    "ConfidenceChangeList = []\n",
    "\n",
    "#Turn lists into one case so they're easy to match\n",
    "\n",
    "DifferentialDict = {\n",
    "    \"Intent 1\": (IntentList),\n",
    "    \"Confidence 1\": (ConfidenceList),\n",
    "    \"Intent 2\": (SecondIntent),\n",
    "    \"Confidence 2\":(SecondConfidence)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "DifferentialDF = pd.DataFrame(DifferentialDict)\n",
    "\n",
    "Differential = DifferentialDF[\"Confidence 1\"] - DifferentialDF[\"Confidence 2\"]\n",
    "\n",
    "DifferentialDict = {\n",
    "    \"Intent 1\": (IntentList),\n",
    "    \"Confidence 1\": (ConfidenceList),\n",
    "    \"Intent 2\": (SecondIntent),\n",
    "    \"Confidence 2\":(SecondConfidence),\n",
    "    \"Difference\": (Differential)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "DifferentialDF = pd.DataFrame(DifferentialDict)\n",
    "\n",
    "\n",
    "\n",
    "IntentList = [item.lower() for item in IntentList] \n",
    "ExpectedList = [item.lower() for item in ExpectedList]\n",
    "\n",
    "\n",
    "if len(IntentList) == len(ExpectedList):\n",
    "    for i in range(len(IntentList)):\n",
    "        if IntentList[i] == ExpectedList[i]:\n",
    "         MatchList.append('Matched')\n",
    "        else: \n",
    "         MatchList.append('Unmatched')\n",
    "\n",
    "CorrectCount = MatchList.count(\"Matched\")\n",
    "IncorrectCount = MatchList.count(\"Unmatched\")\n",
    "LowconfidenceCount = IntentList.count('zlowconf')\n",
    "\n",
    "Total = (CorrectCount + IncorrectCount)\n",
    "Total = CorrectCount / Total\n",
    "Total = round(Total * 100,2)\n",
    "\n",
    "\n",
    "RegressionFile['MatchList'] = MatchList\n",
    "RegressionFile['ConfidenceList'] = ConfidenceList #Look at this before release\n",
    "MatchedQuestion = RegressionFile[(RegressionFile['MatchList'] == 'Matched')]\n",
    "UnmatchedQuestion = RegressionFile[(RegressionFile['MatchList'] == 'Unmatched')]\n",
    "AverageForMatched = round(MatchedQuestion['ConfidenceList'].mean() * 100,2)\n",
    "AverageForUnmatched = round(UnmatchedQuestion['ConfidenceList'].mean() *100,2)\n",
    "AverageConfidence = round(RegressionFile['ConfidenceList'].mean() *100,2)\n",
    "\n",
    "#Convert the data from floats to Strings\n",
    "AverageForMatched = str(AverageForMatched)\n",
    "AverageForUnmatched = str(AverageForUnmatched)\n",
    "AverageConfidence = str(AverageConfidence)\n",
    "Total = str(Total)\n",
    "LowconfidenceCount = str(LowconfidenceCount)\n",
    "\n",
    "LatestHistoricMatchConfidence = []\n",
    "LatestHistoricUnmatchConfidence = []\n",
    "LatestHistoricAverageConfidence = []\n",
    "LatestHistoricCorrectResponse = []\n",
    "LatestHistoricLowConfidence = []\n",
    "LatestHistoricDate = []\n",
    "\n",
    "\n",
    "LatestHistoricMatchConfidence.append(AverageForMatched)\n",
    "LatestHistoricUnmatchConfidence.append(AverageForUnmatched)\n",
    "LatestHistoricAverageConfidence.append(AverageConfidence)\n",
    "LatestHistoricCorrectResponse.append(Total)\n",
    "LatestHistoricDate.append(today)\n",
    "\n",
    "LatestDict = {'Match Confidence': (LatestHistoricMatchConfidence),\n",
    "              'Unmatched Confidence':(LatestHistoricUnmatchConfidence),\n",
    "              'Average Confidence':(LatestHistoricAverageConfidence),\n",
    "              'Correct Response %':(LatestHistoricCorrectResponse),\n",
    "              'Low Confidence':(LowconfidenceCount),\n",
    "              'Date':(LatestHistoricDate)\n",
    "} \n",
    "\n",
    "LatestDF = pd.DataFrame(LatestDict)\n",
    "\n",
    "HistoricDict = { 'Match Confidence':(HistoricMatchConfidence),\n",
    "                 'Unmatched Confidence':(HistoricUnmatchConfidence),\n",
    "                 'Average Confidence':(HistoricAverageConfidence),\n",
    "                 'Correct Response %':(HistoricCorrectResponse),\n",
    "                 'Low Confidence':(HistoricLowConfidence),\n",
    "                 'Date':(HistoricDate)\n",
    "               }\n",
    "\n",
    "DifferentialDict = {\n",
    "    \"Intent 1\": (IntentList),\n",
    "    \"Confidence 1\": (ConfidenceList),\n",
    "    \"Intent 2\": (SecondIntent),\n",
    "    \"Confidence 2\":(SecondConfidence),\n",
    "    \"Difference\": (Differential),\n",
    "    'Matched': (MatchList)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "DifferentialDF = pd.DataFrame(DifferentialDict)\n",
    "\n",
    "\n",
    "#Save Differential Raw data to a file.\n",
    "\n",
    "DifferentialDF.to_csv('DifferentialBreakdown.csv', index=False)\n",
    "\n",
    "\n",
    "DifferentialDF[DifferentialDF.Matched != 'Matched']\n",
    "\n",
    "HistoricDF = pd.DataFrame(HistoricDict)\n",
    "JoinedDF = pd.concat([HistoricDF,LatestDF], join=\"inner\")\n",
    "\n",
    "\n",
    "\n",
    "#Average per intent\n",
    "LowConfidenceRemoved = IntentList\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "UniqueList = list(dict.fromkeys(IntentList))\n",
    "AverageDict = {\n",
    "    'Intent': IntentList,\n",
    "    'Confidence': ConfidenceList\n",
    "}\n",
    "\n",
    "AverageDF = pd.DataFrame(AverageDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JoinedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanDF = AverageDF.groupby(['Intent']).mean()\n",
    "print(MeanDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntentCountDF = AverageDF.groupby(['Intent']).count()\n",
    "print(IntentCountDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This calculates the difference betweeen the first intent and the second intent to show how clearly defined the\n",
    "winning and correct intent is vs it's nearest competitor and then we average that out across each intent\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "DefinitionDF = DifferentialDF.groupby('Intent 1')['Difference'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(DefinitionDF)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixData = {'y_Actual': LowConfidenceRemoved,\n",
    "                       'y_Predicted': ExpectedList \n",
    "                         }\n",
    "\n",
    "DFCM = pd.DataFrame(ConfusionMatrixData, columns=['y_Actual','y_Predicted'])\n",
    "\n",
    "confusion_matrix = pd.crosstab(DFCM['y_Predicted'], DFCM['y_Actual'], rownames=['Actual'], colnames=['Predicted'], normalize='index')\n",
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "confusionmat = sns.heatmap(confusion_matrix, cmap='viridis',linewidths=.2, square=True,)\n",
    "fig = confusionmat.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the updated files to incldue the latest scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create the Regression File to reference in the future\n",
    "\n",
    "RegressionDict = { 'Question':(QuestionList),\n",
    "           'Expected':(ExpectedList),\n",
    "           'Intent':(IntentList),\n",
    "           'Confidence':(ConfidenceList),\n",
    "           'Matched': (MatchList),\n",
    "           'Previous Score':(ScoreList)\n",
    "               }\n",
    "finaldf = pd.DataFrame(RegressionDict)\n",
    "finaldf.to_csv('Regression.csv', index=False)\n",
    "\n",
    "\n",
    "Historic = {'Match Confidence':(HistoricMatchConfidence),\n",
    "            'Unmatched Confidence':(HistoricUnmatchConfidence),\n",
    "            'Average Confidence':(HistoricAverageConfidence),\n",
    "            'Correct Response %':(HistoricCorrectResponse),\n",
    "            'Low Confidence':(HistoricLowConfidence),\n",
    "            'Date':(HistoricDate)\n",
    "               }\n",
    "\n",
    "HistoricDF = pd.DataFrame(Historic)\n",
    "RegressionLogDF = pd.concat([HistoricDF,LatestDF], join=\"inner\")\n",
    "RegressionLogDF.to_csv('RegressionLog.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a box plot for the average per intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxPlot = {\n",
    "    \"Intent\": (IntentList),\n",
    "    \"Confidence\": (ConfidenceList)\n",
    "}\n",
    "\n",
    "BoxPlot = pd.DataFrame(BoxPlot)\n",
    "\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "sns.boxplot( y=BoxPlot[\"Intent\"], x=BoxPlot[\"Confidence\"]);\n",
    "sns.stripplot(x=BoxPlot[\"Confidence\"], y=BoxPlot[\"Intent\"],\n",
    "              size=4, color=\".1\", linewidth=0)\n",
    "fig.savefig('boxplot.jpg', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
